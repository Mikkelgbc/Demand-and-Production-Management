---
title: "Lecture 05 - Forecasting Workshop 2"
author:
    
  - name: [Mikkel Groth B Christensen]
    affiliation: cand.merc (OSCM)
date: "`r Sys.Date()`"
repository_url: [https://github.com/Mikkelgbc/Demand-and-Production-Management.git]
creative_commons: CC BY-NC
output:
  distill::distill_article:
    toc: true
    toc_depth: 3
    toc_float: false
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
if (interactive()) setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working dir to current file location
knitr::opts_chunk$set(
  cache = TRUE, autodep = TRUE,
  echo = TRUE, 
  layout="l-page", fig.width = 12)
```


# Load Packages

```{r}
library(forecast)
library(fpp2)
library(stats)
library(graphics)
library(rmarkdown)
library(dplyr)
library(cowplot)

```


# ARIMA Models

## Exercise 1

In this exercise, we use the 'austa' data set, which is the total number of international visitors to Australia (in millions) for the period 1980-2015.

### a) Use auto.arima() to find an appropriate ARIMA model.

```{r}
austa_arima <- auto.arima(austa) %>% 
  print()
```

What model was selected: The most appropriate model is the ARIMA(0,1,1) model with drift.


Check that the residuals look like white noise:

```{r}
checkresiduals(austa_arima)
```

The residuals looks fairly random and normally distributed.


Plot forecasts for the next 10 periods:

```{r}
austa011a <- forecast(austa_arima)
autoplot(austa011a)
```


### b) Plot forecasts from an ARIMA(0,1,1) model with no drift and compare these to part a.

```{r}
austa011b <- forecast(arima(austa, c(0,1,1)), h=10)
autoplot(austa011b)
```

The forecast is not drifting upwards as in a)


Remove the MA term and plot again:

```{r}
austa010 <- forecast(arima(austa, c(0,1,0)), h=10)
autoplot(austa010)
```

The confidence interval looks smaller and therefore more accurate.


### c) Plot forecasts from an ARIMA(2,1,3) model with drift.

```{r}
austa213 <- forecast(Arima(austa, c(2,1,3),include.drift= TRUE), h=10)
autoplot(austa213)
```

Remove the constant and see what happens:

The model is not stationary anymore, so we cannot do it.


### d) Plot forecasts from an ARIMA(0,0,1) model with a constant.

```{r}
austa001 <- forecast(arima(austa, c(0,0,1)), include.constant=TRUE, h=10)
autoplot(austa001)
```

Remove the MA term and plot again

```{r}
austa000 <- forecast(arima(austa, c(0,0,0)), include.constant=TRUE, h=10)
autoplot(austa000)
```

### e) Plot forecasts from an ARIMA(0,2,1) model with no constant.

```{r}
austa021 <- forecast(arima(austa, c(0,2,1)), include.constant=FALSE, h=10)
autoplot(austa021)
```

Now, lets look at all of the plot together:

```{r}
plot_grid(autoplot(austa011a), autoplot(austa011b), autoplot(austa010), autoplot(austa213), autoplot(austa001), autoplot(austa000), autoplot(austa021), ncol = 2)
```

## Exercise 2

In this exercise, we consider the time series sheep, the sheep population of England and Wales from
1867-1939.

```{r}
autoplot(sheep)
```


Assume you decide to fit the model described in the text. What sort of ARIMA model is this (i.e., what are p, d, and q)?

It is ARIMA(3, 1, 0) model.


### b) By examining the ACF and PACF of the differenced data, explain why this model is appropriate.

```{r}
ggtsdisplay(diff(sheep))
```

ACF plot shows sinusoidally decreasing autocorrelation values, while PACF plot shows significant spikes at lag 1 to 3, but no  beyond lag 3. Therefore ARIMA(3, 1, 0) is appropriate.


### c) Without using the forecast function, calculate forecasts for the next three years (1940-1942).

Using the formula stated in the text, we calculate the forecasts for the next three years:

```{r}
sheep_1940 = 1797 + 0.421 * (1797 - 1791) + (-0.202) * (1791 - 1627) + (-0.304) * (1627 - 1665)
sheep_1941 = sheep_1940 + 0.421 * (sheep_1940 - 1797) + (-0.202) * (1797 - 1791) + (-0.304) * (1791 - 1627)
sheep_1942 = sheep_1941 + 0.421 * (sheep_1941 - sheep_1940) + (-0.202) * (sheep_1940 - 1797) + (-0.304) * (1797-1791)

c(sheep_1940, sheep_1941, sheep_1942)
```

### d) Fit the model in R and obtain the forecasts using forecast. How are they different from yours? Why?

```{r}
sheep_arima <- forecast(arima(sheep, c(3,1,0)), h=3)
sheep_arima$mean
```

The calculated forecasts are almost the same and the only differnce is down to the number of decimals used.

Small differences in the coefficients made the difference between the first forecast, and then the forecast values were used to calculate the next time point's forecasts, making the difference increasingly bigger.

If we use the coefficients from the arima function, then we can calculate the same forecast values:

```{r}
coef1 <- sheep_arima$model$coef[1]
coef2 <- sheep_arima$model$coef[2]
coef3 <- sheep_arima$model$coef[3]

c(coef1, coef2, coef3)
```

```{r}
sheep.1940.new = 1797 + coef1*(1797 - 1791) + coef2*(1791 - 1627) + coef3*(1627 - 1665)

sheep.1941.new = sheep.1940.new + coef1*(sheep.1940.new - 1797) + coef2*(1797 - 1791) +
  coef3*(1791 - 1627)

sheep.1942.new = sheep.1941.new + coef1*(sheep.1941.new - sheep.1940.new) + 
  coef2*(sheep.1940.new - 1797) + coef3*(1797 - 1791)


c(sheep.1940.new, sheep.1941.new, sheep.1942.new)
```

Above calculation confirms what I said about the differences.


## Exercise 3

In this exercise, we consider the data set 'usmelec', which shows the total net generation of electricity (in billion kilowatt hours) by the U.S. electric industry (monthly for the period January 1973 - June 2013). In general there are two peaks per year: in mid-summer and mid-winter.


### a) Examine the 12-month moving average of this series to see what kind of trend is involved.

We make a time series plot:

```{r}
autoplot(usmelec, ylab = "Generation of electricity", 
    xlab = "Year", 
    main = "Total net generation of electricity (in billion kilowatt hours) by the U.S.")
```

It's hard to see the average trend, due to the seasonality (and probably also cyclicity)

We therefore add a moving average line reflecting the average for each year (MA=12):

```{r}
plot(usmelec, col = "grey") +
  lines(ma(usmelec, order = 12), col = "red")
```

Taking the 12-month moving average makes it easier to see a clear trend. Aside from a noticable dip in the early-mid 1980s there is a consistent increasing linear trend until the late 2000s where it dips and flattens to the end of the data in 2013.


### b) Do the data need transforming? If so, find a suitable transformation.

We calculate the lambda value to check if it is equal to 0.

```{r}
lambda <- BoxCox.lambda(usmelec) %>% 
  print()
```

We get R to transform the data:

```{r}
autoplot(BoxCox(usmelec, lambda))
```

We plot both plots to compare the original and transformed data:

```{r}
plot_grid(autoplot(usmelec), autoplot(BoxCox(usmelec, lambda)), nrow=2)
```


### c) Are the data stationary? If not, find an appropriate differencing which yields stationary data.

The ACF plot is useful for identifying non-stationary time series. For a stationary time series, the ACF will drop to zero relatively quickly, while the ACF of non-stationary data decreases slowly.


```{r}
acf(usmelec)
```

It looks like the ACF is slowly decreasing, indicating that this is a non-stationary time series (which is expected, looking at the plot from question a)

We can use he 'ndiffs' function to get an estimate of how many differencing iterations is necessary for making the time series stationary.

```{r}
ndiffs(usmelec)
```

One iteration of differencing is sufficient.

We check that claim:

```{r}
acf(diff(usmelec))
```

The differenced data series hover around 0 and are therefore stationary.


### d) Identify a couple of ARIMA models that might be useful in describing the time series. 

An autoregressive integrated moving average model (ARIMA) examines the differences between values in the series instead of through actual values.

3 components of ARIMA:
Autoregression (AR) - refers to a model that shows a changing variable that regresses on its own lagged, or prior, values.

Integrated (I) represents the differencing of raw observations to allow for the time series to become stationary, i.e., data values are replaced by the difference between the data values and the previous values.

Moving average (MA) incorporates the dependency between an observation and a residual error from a moving average model applied to lagged observations.


To get a better indication of the data at hand, we make a decomposition of the time series, showing us the trend, seasonality and randomness.

```{r}
plot(decompose(usmelec))
```

We here see a clear upward trend with high seasonality and changing randomness trough-out the time series.


Which of your models is the best according to their AIC values?

Using the 'auto.arima' function, we can find the best fitting ARIMA model.

```{r}
usmelec_auto_arima <- auto.arima(usmelec) %>% 
  print()
```

This means that we need to use a Seasonal ARIMA model using 1 lag, with no differencing and double moving average (1,0,2). In the seasonal part is used 0 lag, single differencing and 1 period moving average (0,1,1).

The AIC is 3282,6


### e) Estimate the parameters of your best model and do diagnostic testing on the residuals. Do the residuals resemble white noise?

```{r}
checkresiduals(usmelec_auto_arima)
```

```{r}
summary(usmelec_auto_arima)
```

It looks good.


### f) Forecast the next 15 years of electricity generation by the U.S. electric industry and check the accuracy of your forecasts.

We start by forecasting for the next 15 years using our ARIMA model:

```{r}
usmelec_arima_forecast <- forecast(usmelec_auto_arima, h = 180)

usmelec_arima_forecast %>% 
  as.data.frame() %>% 
  paged_table()
```


We plot the forecast:

```{r}
plot(usmelec_arima_forecast,
     ylab = "Generation of electricity")
lines(ma(usmelec, 12), col = "red")
```


We read in the data for validation:

```{r}
elecData <- readxl::read_excel("Workshop II - Data.xlsx")
elec1120 <-ts(elecData[,"electricity_generation"]/1000,
start = c(1973,1), frequency = 12)
```


### g) Compare the forecasts obtained using ets().

We plot the actual data:

```{r}
autoplot(elec1120, series = "New") +
  autolayer(usmelec, series = "Old")
```

```{r}
usmelec_arima_plot <- autoplot(usmelec_arima_forecast) +
  autolayer(window(elec1120, start=c(2013,7)), series = "Actual data")

usmelec_arima_plot
```

You can see the effect of Covid-19 in the start of 2020 of the actual data.


We forecast using ets:

```{r}
forecast(ets(elec1120))
```

```{r}
usmelec_ets <- forecast(ets(usmelec, damped = TRUE, lambda=lambda),h=180)

usmelec_ets %>% 
  as.data.frame() %>% 
  paged_table()
```

We plot the forecast against the actual data:

```{r}
usmelec_etc_plot <- autoplot(usmelec_ets) +
  autolayer(window(elec1120, start=c(2013,7)), series = "Actual data")

usmelec_etc_plot
```

We compare the accuracy of ARIMA forecast with the ETS forecast

```{r}
accuracy(usmelec_arima_forecast,elec1120)
accuracy(usmelec_ets, elec1120)
```

We see that the ARIMA forecast has a lower RMSE value and are therefore more accurate.


### h) How many years of forecasts do you think are suficiently accurate to be usable?

The forecast do seems to be pretty accurate besides the COvid-19 effect, so probablty 5-10 years would be a good forecasting horizon in this case.


### i) Try using a non-seasonal model applied to the seasonally adjusted data obtained from STL. The

```{r}
usmelec_stlf <- stlf(usmelec, h=180, lambda = lambda, method = "arima")

usmelec_stlf %>% 
  as.data.frame() %>% 
  paged_table()
```

We plot the forecast:

```{r}
usmelec_stlf_plot <- autoplot(usmelec_stlf) +
  autolayer(window(elec1120, start=c(2013,7)), series = "Actual data")

usmelec_stlf_plot
```

We compare the accuracy of the forecast compared to the ARIMA and ETS method:

```{r}
accuracy(usmelec_arima_forecast, elec1120)
accuracy(usmelec_ets, elec1120)
accuracy(usmelec_stlf, elec1120)
```

The stl method has the lowest RMSE and are therefore the best forecast method.


# Neural Networks and Validation

## Exercise 4

Calculate the neural network forecast by nnetar() for the time series from the previous exercise. Use a forecasting period of 15 years, the data from usmelec and compare the accuracy to the time series from the Excel file.


We check the proposed neural network:

```{r}
nnetar(usmelec, lambda = lambda)
```

We make a forecast for the next 15 years using the neural network:

```{r}
usmelec_NN <- forecast(nnetar(usmelec, lambda = lambda), h=180)

usmelec_NN %>%
  as.data.frame() %>%
  paged_table()
```


We plot the forecast:

```{r}
usmelec_NN_plot <- autoplot(usmelec_NN) +
  autolayer(window(elec1120, start=c(2013,7)), series = "Actual data")

usmelec_NN_plot
```
We compare the accuracy of the forecast compared to the ARIMA, ETS and STL method:

```{r}
accuracy(usmelec_arima_forecast, elec1120)
accuracy(usmelec_ets, elec1120)
accuracy(usmelec_stlf, elec1120)
accuracy(usmelec_NN, elec1120)
```

We plot all the forecast to see the difference:

```{r}
plot_grid(usmelec_arima_plot, usmelec_etc_plot, usmelec_stlf_plot, usmelec_NN_plot, labels="AUTO", nrow=4)
```


## Exercise 5

In this exercise, we consider the retail data in exercise 2 from workshop 1, and forecast the time series for the next three years.


### a) Develop an appropriate seasonal ARIMA model and forecast

We load the data set (and chose a time series):

```{r}
retaildata <- readxl::read_excel("Australian Retail Data.xlsx", skip=1)
myretail <- ts(retaildata$A3349791W, frequency=12, start=c(1982,4))
```


We find an appropriate ARIMA model

```{r}
auto.arima(myretail)
```

We forecast using the ARIMA model

```{r}
myretail_arima <- forecast(auto.arima(myretail), h=46)

myretail_arima %>% 
  as.data.frame() %>% 
  paged_table()
```

We plot the forecast:

```{r}
plot(myretail_arima)
```

We check the accuracy of the forecast:

```{r}
accuracy(myretail_arima)
```

### b) Create the neural network forecast by using nnetar(). Use the whole data set as training data.

We check the proposed neural network:

```{r}
nnetar(myretail)
```

We forecast the next 3 years using the neural network:

```{r}
myretail_NN <- forecast(nnetar(myretail), h=46)

myretail_NN %>% 
  as.data.frame() %>% 
  paged_table()
```

We plot the forecast:

```{r}
plot(myretail_NN)
```

We check the residuals:

```{r}
checkresiduals(myretail_NN)
```

We chech the accuracy of the forecast:

```{r}
accuracy(myretail_NN)
```

The forecast seems worse looking at the higher RSME value compared to the arima model.


### c) Split the data in two parts

The training set should end by December 2010 and the test set start by (January) 2011.

```{r}
training_set <- window(myretail, end=c(2010, 12))
test_set <- window(myretail, end=c(2011))
```

We plot the two data sets:

```{r}
autoplot(myretail) +
  autolayer(training_set, series = "Training")+
  autolayer(test_set, series = "Test")
```


### d) Calculate the forecasts using naive (by snaive(training data)), ARIMA and neural network forecast for the training data.

We calculate the forecast using snaive:

```{r}
ts_snaive <- snaive(training_set, h=36, lambda = 0)

ts_snaive %>% 
  as.data.frame() %>% 
  select("Point Forecast") %>%
  paged_table()
```


We calculate the forecast using arima:

```{r}
ts_arima <- forecast(auto.arima(training_set, seasonal = TRUE, lambda = 0),h=36)

ts_arima %>% 
  as.data.frame() %>% 
  select("Point Forecast") %>%
  paged_table()
```

We calculate the forecast using neural network:

```{r}
ts_NN <- forecast(nnetar(training_set, lambda = 0), h=36)

ts_NN %>% 
  as.data.frame() %>% 
  paged_table()
```

We plot the forecasts:

```{r}
ts_snaive_plot <- autoplot(ts_snaive) +
  autolayer(test_set, series = "Test set")

ts_arima_plot <- autoplot(ts_arima) +
  autolayer(test_set, series = "Test set")

ts_NN_plot <- autoplot(ts_NN) +
  autolayer(test_set, series = "Test set")

plot_grid(ts_snaive_plot, ts_arima_plot, ts_NN_plot, nrow = 3)
```


### e) Compare the accuracy between the forecasts (by accuracy(forecast, test data)). What can you see?

```{r}
accuracy(ts_snaive, test_set)
accuracy(ts_arima, test_set)
accuracy(ts_NN, test_set)
```

The neural network seems to make the best forecast with the lowest RMSE value.


### f) Check the residuals. Do the residuals appear to be uncorrelated and normally distributed?

We check the residual for the Snaive:

```{r}
checkresiduals(ts_snaive)
```

We check the residual for the ARIMA:

```{r}
checkresiduals(ts_arima)
```

We check the residual for the Neural Network:

```{r}
checkresiduals(ts_NN)
```

The residuals appear to be uncorrelated and normally distributed.


### g) How sensitive are the accuracy measures to the training/test split?

No idea :)
