---
title: "Lecture 03 - Forecasting Workshop"
author:
  - name: [Mikkel Groth B Christensen]
    affiliation: cand.merc (OSCM)
    
date: "`r Sys.Date()`"
repository_url: [https://github.com/Mikkelgbc/Demand-and-Production-Management.git]
creative_commons: CC BY-NC
output:
  distill::distill_article:
editor_options: 
  chunk_output_type: inline
---

```{r, include=FALSE}
if (interactive()) setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working dir to current file location
knitr::opts_chunk$set(
  cache = TRUE, autodep = TRUE,  # use this option so compile the document faster (you may comment it out at the final report)
  echo = TRUE, 
  layout="l-page", fig.width = 12
  )
# use xaringan::inf_mr() for instant preview
```

# Load Packages

```{r}
library(forecast)
library(fpp2)
library(stats)
library(graphics)
library(skimr)
library(gridExtra)
library(rmarkdown)
```

# Getting Started

## Exercise 1

### hsales

Monthly sales of new one-family houses sold in the USA since 1973.

```{r}
autoplot(hsales)
ggseasonplot(hsales)
ggsubseriesplot(hsales)
gglagplot(hsales)
ggAcf(hsales)
```

Comment: There is both sesonality and cyclicity. Trend can be discussed as the mean is more or less unchanged.


### usdeaths

Monthly accidental deaths in USA.

```{r}
autoplot(usdeaths)
ggseasonplot(usdeaths)
ggsubseriesplot(usdeaths)
gglagplot(usdeaths)
ggAcf(usdeaths)
```

Comment: There is both seasonality and cyclicity. The trend can be argued to be downward.


### bricksq

Australian quarterly clay brick production: 1956â€“1994.

```{r}
autoplot(bricksq)
ggseasonplot(bricksq)
ggsubseriesplot(bricksq)
gglagplot(bricksq)
ggAcf(bricksq)
```

Comment: There is a is a clear trend and cyclicity.


### sunspotarea

Annual averages of the daily sunspot areas (in units of millionths of a hemisphere) for the full sun. Sunspots are magnetic regions that appear as dark spots on the surface of the sun. The Royal Greenwich Observatory compiled daily sunspot observations from May 1874 to 1976. Later data are from the US Air Force and the US National Oceanic and Atmospheric Administration. The data have been calibrated to be consistent across the whole history of observations.

```{r}
autoplot(sunspotarea)
gglagplot(sunspotarea)
ggAcf(sunspotarea)
```

Comment: There is no seasonaltity, but a clear cyclicity,

## Exercise 2

### a) Load data

```{r}
retaildata <- readxl::read_excel("Australian Retail Data.xlsx", skip=1)
```

### b) Chose time series

A3349791W = Turnover; New South Wales; Other recreational goods retailing;

```{r}
mytimeseries <- ts(retaildata$A3349791W, frequency=12, start=c(1982,4))
```

### c) Analyse time series

```{r}
autoplot(mytimeseries)
ggseasonplot(mytimeseries)
ggsubseriesplot(mytimeseries)
gglagplot(mytimeseries)
ggAcf(mytimeseries)
```

Comment: There is a clear upward trend, and a clear seasonality with a peak around december.

# Time Series Regression

## Exercise 3

Daily electricity demand for Victoria, Australia, during 2014 is contained in elecdaily. The data for the first 20 days can be obtained as follows.


### Load data
```{r}
daily20 <- head(elecdaily,20)

daily20 %>% 
  as.data.frame() %>% 
  paged_table()
```


### Check plots

```{r}
autoplot(daily20, facets=TRUE)
```

Comment: We can clearly see a drop-off when its not a workday.


### a) Plot the data and explain the linear relationship between demand and temperature

```{r}
daily20 %>% 
  as.data.frame() %>% 
  ggplot(aes(Temperature, Demand)) +
  geom_point()+
  geom_smooth(method = "lm", se=FALSE)
```

Comment: Australia has a very warm climate and therefore don't need to use electricity to heat their houses. Instead they need to cool there house when it is hot using Air Condition, which uses electricity. Therefore does the demand for electricity increase with the temperature as the AC needs to work more to cool down the house.


### b) Plot the residual plot
```{r}
fit <- tslm(Demand ~ Temperature, data=daily20)
checkresiduals(fit)
```

Comment: There is no clear trend in the residuals and the they are fairly normally distributed.


### cd) Forecast the next day using diffferent maximum temperatures

```{r}
forecast(fit, newdata=data.frame(Temperature=c(15,35))) %>% 
  as.data.frame() %>% 
  paged_table()
```

Comment: The demand forecast for a day with a temperature of 15 degress is 140,57, and for a day with a temperature of 30 degress is 275,71. Given that we have only analyses the last 20 days, we can't really trust this forecast.


### e) Plot Demand vs Temperature for all of the available data in elecdaily.

```{r}
elecdaily %>% 
  as.data.frame() %>% 
  ggplot(aes(Temperature, Demand)) +
  geom_point()+
  geom_smooth(method = "lm", se=FALSE)
```

Comment: This shows a U-formed trend, which is bad for our linear model.


## Exercise 4

### a) Produce a time plot of the data

```{r}
autoplot(fancy)
ggsubseriesplot(fancy)
```

Comment: There is a clear trend and seasonality in the data, with rises in marts and december (just like indicated in the text)


### b) Explain why it is necessary to take logarithms of these data before fitting a model.

Due to the clear upward trend, it is necessary to use a logarithmic scale to ensure stabilization and ensure that there are no "heteroscedasticity".


### c) Use R to fit a regression model to the logarithms of these sales data

See comments in code for procedure:

```{r}
# First we create a new data set using the log() function (takes the log of fancy)
log_fancy <- log(fancy)

# Then we create a dummy variable for the festival called 'dummy_fest'. We create the dummy from 0 to the length of fancy.
dummy_fest = rep(0, length(fancy))

# We sequence it using 'seq_along'and give every third dummy the value 1 (to indicate the festival month, marts, every year)
dummy_fest[seq_along(dummy_fest) %% 12 == 3] <- 1

# We give the first marts (the third dummy) a value of 0 as the festival first started in 1988 (and no 1887)
dummy_fest[3] <- 0

# We transform the dummy into a time series using a frequency of 12 months and a start in january 1987.
dummy_fest <- ts(dummy_fest, frequency = 12, start = c(1987,1))

# We create a new dataset combining the two
my_data <- data.frame(log_fancy, dummy_fest)

# We fit a regression model to the sales data using trend, season and our dummy
fit <- tslm(log_fancy ~ trend + season + dummy_fest, data=my_data)

# We create yet another data set with 12 values
future_data <- data.frame(dummy_fest=rep(0,12))

# We assign 1 to the third value
future_data[3,] <- 1

# We forecast the next 12 months using our fitted regression model
forecast(fit, newdata = future_data) %>% 
  as.data.frame() %>% 
  paged_table()
```

Comment:



### d) Plot the residuals against time and against the fitted values.

```{r}
checkresiduals(fit)
```

Comment: 



### e) Do boxplots of the residuals for each month.

```{r}
boxplot(resid(fit) ~ cycle(resid(fit)))
```

Comment: 



### f) What do the values of the coeffcients tell you about each variable?

```{r}


```

Comment: 



### g) Use your regression model to predict the monthly sales for 1994, 1995, and 1996.

```{r}
# We create another data set with 36 values
future_data <- data.frame(dummy_fest=rep(0,36))

# We forecast the next 36 months using our fitted regression model
pred <- forecast(fit, newdata = future_data)

as.data.frame(pred) %>% 
  paged_table()
```

Comment: 



### h) Transform your predictions and intervals to obtain predictions and intervals for the raw data.

```{r}
# We transform our forecast to a dataframe
df <- as.data.frame(pred)

# We take the exponential values to reverse the log() we used earlier
df <- exp(df)
paged_table(df)
```

Comment:



### i) How could you improve these predictions by modifying the model?

We could consider using a dynamic-regression model which works better when we haveautocorrelation remaining in the residuals.


# Exponential Smoothing

## Exercise 5

### a) Plot the series

```{r}
autoplot(books)
```

Comment: There is a upward trend.


### b) Use the ses() function to forecast each series

```{r}
# Simple Exponential Smoothing for Paperback
fc_paper <- ses(books[,1])

# Simple Exponential Smoothing for Hardcover
fc_cover <- ses(books[,2])

# Forecast for Paperback
forecast(fc_paper) %>% 
  as.data.frame() %>% 
  paged_table()

# Forecast for Hardcover
forecast(fc_cover) %>% 
  as.data.frame() %>% 
  paged_table()

# Simple Exponential Smoothing plot for Paperback
plot_paper1 <- autoplot(fc_paper) +
  autolayer(fitted(fc_paper), series= "Paperback") +
  xlab("Time") + ylab("Sales")

# Simple Exponential Smoothing plot for Hardcover
plot_cover1 <- autoplot(fc_cover) +
  autolayer(fitted(fc_cover), series= "Hardcover") +
  xlab("Time") + ylab("Sales")

# Arrange plots
grid.arrange(plot_paper1,plot_cover1)

```


### c) Compute the RMSE values for the training data in each case.

```{r}
# RMSE for Paperback
accuracy(fc_paper)[2]
```

```{r}
# RMSE for Hardcover
accuracy(fc_cover)[2]
```

Comment: 



### d) Apply Holt's linear method to the paperback and hardback series and compute four-day forecasts in each case.

```{r}
# Holt forecasting for Paperback
holt_paper <- holt(books[,1], h=4)

holt_paper %>% 
  as.data.frame() %>% 
  paged_table()
```

```{r}
# Holt forecasting for Hardcover
holt_cover <- holt(books[,2], h=4)

holt_cover %>% 
  as.data.frame() %>% 
  paged_table()
```


Comment: 



### e) Compare the RMSE measures of Holt's method for the two series to those of simple exponential smoothing in the previous.

```{r}
# RMSE for Paperback
accuracy(holt_paper)[2]
```

```{r}
# RMSE for Hardcover
accuracy(holt_cover)[2]
```

Comment: 



### f) Compare the forecasts for the two series using both methods.

```{r}
# Holt plot of Paperback
plot_paper2 <- autoplot(holt_paper) +
  autolayer(fitted(fc_paper), series= "Paperback") +
  xlab("Time") + ylab("Sales")

# Holt plot of Hardcover
plot_cover2 <- autoplot(holt_cover) +
  autolayer(fitted(fc_cover), series= "Hardcover") +
  xlab("Time") + ylab("Sales")

# Comparison of Paperback
grid.arrange(plot_paper1, plot_paper2)

# Comparison of Hardcover
grid.arrange(plot_cover1, plot_cover2)
```

Comment: 



### g) Calculate a 95% prediction interval for the first forecast for each series, using the RMSE values and assuming normal errors.

```{r}

```

Comment: 



## Exercise 6


### a) Why is multiplicative seasonality necessary for this series?

```{r}
autoplot(mytimeseries)
```
```

Comment: 


### b) Apply Holt-Winters' multiplicative method to the data. Experiment with making the trend damped.

```{r}

```

Comment: 


### c) Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

```{r}

```

Comment: 


### d) Check that the residuals from the best method look like white noise.

```{r}

```

Comment: 


### e) Now find the test set RMSE, while training the model to the end of 2010.

```{r}

```

Comment: 

